{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_train = json.load(open('C:/VQA/data/vqa_train.json'))\n",
    "questions =[]\n",
    "answers =[]\n",
    "\n",
    "for i in range(len(vqa_train)):\n",
    "    questions.append(vqa_train[i]['question'][:-1])\n",
    "    answers.append(vqa_train[i]['ans'])\n",
    "questions=questions[:1000]\n",
    "answers = answers[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=[]\n",
    "from nltk.tokenize import word_tokenize\n",
    "for que in questions:\n",
    "    tokenize_word = word_tokenize(que)\n",
    "    for word in tokenize_word:\n",
    "        vocab.append(word)\n",
    "for ans in answers:\n",
    "    tokenize_word = word_tokenize(ans)\n",
    "    for word in tokenize_word:\n",
    "        vocab.append(word)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(vocab)\n",
    "vocab_len = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is this photo taken looking through\n",
      "What position is this man playing\n",
      "[1129, 593, 864, 203, 435, 761, 887]\n",
      "[1129, 100, 593, 864, 227, 57]\n",
      "[110]\n",
      "[760]\n"
     ]
    }
   ],
   "source": [
    "embedded_questions = [one_hot(ques,vocab_len) for ques in questions]\n",
    "print(questions[0])\n",
    "print(questions[1])\n",
    "print(embedded_questions[0])\n",
    "print(embedded_questions[1])\n",
    "\n",
    "\n",
    "embedded_ans = [one_hot(ans,vocab_len) for ans in answers]\n",
    "print(embedded_ans[0])\n",
    "print(embedded_ans[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sentence =17\n",
      "Longest sentence =9\n"
     ]
    }
   ],
   "source": [
    "question_count = lambda sentence: len(word_tokenize(sentence))\n",
    "longest_question = max(questions, key=question_count)\n",
    "length_long_question = len(word_tokenize(longest_question))\n",
    "print('Longest sentence ='+str(length_long_question))\n",
    "ans_count = lambda sentence: len(word_tokenize(sentence))\n",
    "longest_ans = max(answers, key=ans_count)\n",
    "length_long_ans = len(word_tokenize(longest_ans))\n",
    "print('Longest sentence ='+str(length_long_ans))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 17)\n",
      "[1129  593  864  203  435  761  887    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "[1129  100  593  864  227   57    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "(1000, 1216)\n"
     ]
    }
   ],
   "source": [
    "padded_questions = pad_sequences(embedded_questions, length_long_question, padding='post')\n",
    "print(padded_questions.shape)\n",
    "print(padded_questions[0])\n",
    "print(padded_questions[1])\n",
    "padded_answers = pad_sequences(embedded_ans, vocab_len, padding='post')\n",
    "\n",
    "#padded_answers =  [item[0] for item in padded_answers]\n",
    "print(padded_answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_len,32,input_length=length_long_question))\n",
    "model.add(LSTM(256,dropout=0.2))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(vocab_len,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 17, 32)            38912     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 256)               295936    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1216)              312512    \n",
      "=================================================================\n",
      "Total params: 647,360\n",
      "Trainable params: 647,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -278.9249 - acc: 0.9967\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -282.7874 - acc: 0.9967\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -286.6269 - acc: 0.9967\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -290.4801 - acc: 0.9967\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -294.3026 - acc: 0.9967\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -298.1439 - acc: 0.9967\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -302.0284 - acc: 0.9967\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -305.9048 - acc: 0.9967\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -309.7786 - acc: 0.9967\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: -313.8665 - acc: 0.99 - 4s 4ms/step - loss: -313.6671 - acc: 0.9967\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -317.5061 - acc: 0.9967\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -321.3776 - acc: 0.9967\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -325.2496 - acc: 0.9960: \n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -329.1209 - acc: 0.9964\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -332.9549 - acc: 0.9967\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -336.7894 - acc: 0.9967\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -340.6468 - acc: 0.9967\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -344.4791 - acc: 0.9967: 1s\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -348.3600 - acc: 0.9967: 0s - loss: -346.45\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -352.1801 - acc: 0.9967\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -355.9822 - acc: 0.9967\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -359.8316 - acc: 0.9967\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -363.6956 - acc: 0.9967\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -367.5514 - acc: 0.9967\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -371.4125 - acc: 0.9967\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -375.2522 - acc: 0.9967\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -379.1035 - acc: 0.9967\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -382.9585 - acc: 0.9967\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -386.8128 - acc: 0.9967\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -390.6251 - acc: 0.9967\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -394.4551 - acc: 0.9967\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -398.3414 - acc: 0.9967\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -402.1964 - acc: 0.9967\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -406.0615 - acc: 0.9967\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -409.8973 - acc: 0.9967\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -413.7767 - acc: 0.9967\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -417.7367 - acc: 0.9967\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -421.6100 - acc: 0.9967\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -425.4984 - acc: 0.9967\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -429.3994 - acc: 0.9967\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -433.2422 - acc: 0.9967\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -437.1206 - acc: 0.9967\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -441.0073 - acc: 0.9967\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -444.8850 - acc: 0.9967\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -448.7807 - acc: 0.9967\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -452.6259 - acc: 0.9967\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -456.4899 - acc: 0.9967\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -460.3615 - acc: 0.9967: 1s\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -464.2131 - acc: 0.9967\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -468.1015 - acc: 0.9967\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -471.9498 - acc: 0.9967\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -475.8307 - acc: 0.9967\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -479.6647 - acc: 0.9967\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -483.5072 - acc: 0.9967\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -487.3356 - acc: 0.9967\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -491.2291 - acc: 0.9967\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -495.0848 - acc: 0.9967\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -498.9441 - acc: 0.9967\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -502.8220 - acc: 0.9967\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -506.7150 - acc: 0.9967\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -510.5836 - acc: 0.9967\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -514.4541 - acc: 0.9967\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -518.3530 - acc: 0.9967\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -522.2028 - acc: 0.9967: 0s - loss:\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -526.0644 - acc: 0.9967\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -529.8917 - acc: 0.9967\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -533.7840 - acc: 0.9967\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -537.6053 - acc: 0.9960\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -541.4529 - acc: 0.9960\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: -545.3129 - acc: 0.9967\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: -549.1926 - acc: 0.9967\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -553.0399 - acc: 0.9967\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -556.8890 - acc: 0.9967\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -560.7354 - acc: 0.9967\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -564.5987 - acc: 0.9967\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -568.4288 - acc: 0.9967\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -572.3038 - acc: 0.9967\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -576.1469 - acc: 0.9967: 0s - loss: -579.7250\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -579.9779 - acc: 0.9967\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 3s 3ms/step - loss: -583.8566 - acc: 0.9967\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -587.7221 - acc: 0.9967\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -591.5919 - acc: 0.9967\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -595.4086 - acc: 0.9967: 1s\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -599.2760 - acc: 0.9967\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -603.1872 - acc: 0.9967\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -607.0277 - acc: 0.9967\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -610.9134 - acc: 0.9967\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -614.7928 - acc: 0.9967\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -618.6714 - acc: 0.9967: 1s -\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -622.5259 - acc: 0.9967\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -626.3874 - acc: 0.9967\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -630.2376 - acc: 0.9967\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -634.0946 - acc: 0.9967\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -637.9704 - acc: 0.9967\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -641.8222 - acc: 0.9967\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -645.6771 - acc: 0.9967\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -649.5201 - acc: 0.9967\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -653.3817 - acc: 0.9960\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -657.2384 - acc: 0.9965\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -661.1134 - acc: 0.9967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x288cca03a20>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_questions,padded_answers,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 897us/step\n",
      "Accuracy: 99.670953\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_questions, padded_answers, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1129  593  864  203  435  761  887    0    0    0    0    0    0    0\n",
      "     0    0    0]]\n",
      "(1, 17)\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "[[1.00000000e+00 1.00000000e+00 1.00000000e+00 ... 1.29342079e-05\n",
      "  7.74860382e-06 1.04010105e-05]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "test_question =padded_questions[0].reshape((1,-1))\n",
    "print(test_question)\n",
    "# test_question  =np.reshape(test_question,(1,))\n",
    "print(test_question.shape)\n",
    "test_output = model.predict(test_question,verbose=1)\n",
    "print(test_output)\n",
    "test_output = np.argmax(test_output.reshape((-1,1)))\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
