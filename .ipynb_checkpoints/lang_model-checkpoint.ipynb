{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_train = json.load(open('C:/VQA/data/vqa_train.json'))\n",
    "questions =[]\n",
    "answers =[]\n",
    "\n",
    "for i in range(len(vqa_train)):\n",
    "    questions.append(vqa_train[i]['question'][:-1])\n",
    "    answers.append(vqa_train[i]['ans'])\n",
    "# questions=questions[:1000]\n",
    "# answers = answers[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=[]\n",
    "from nltk.tokenize import word_tokenize\n",
    "for que in questions:\n",
    "    tokenize_word = word_tokenize(que)\n",
    "    for word in tokenize_word:\n",
    "        vocab.append(word)\n",
    "for ans in answers:\n",
    "    tokenize_word = word_tokenize(ans)\n",
    "    for word in tokenize_word:\n",
    "        vocab.append(word)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(vocab)\n",
    "vocab_len = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[932, 120, 764, 128, 1190, 593, 975]\n",
      "[932, 675, 120, 764, 531, 639]\n",
      "[1208]\n",
      "[70]\n"
     ]
    }
   ],
   "source": [
    "embedded_questions = [one_hot(ques,vocab_len) for ques in questions]\n",
    "print(embedded_questions[0])\n",
    "print(embedded_questions[1])\n",
    "\n",
    "\n",
    "embedded_ans = [one_hot(ans,vocab_len) for ans in answers]\n",
    "print(embedded_ans[0])\n",
    "print(embedded_ans[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sentence =17\n",
      "Longest sentence =9\n"
     ]
    }
   ],
   "source": [
    "question_count = lambda sentence: len(word_tokenize(sentence))\n",
    "longest_question = max(questions, key=question_count)\n",
    "length_long_question = len(word_tokenize(longest_question))\n",
    "print('Longest sentence ='+str(length_long_question))\n",
    "ans_count = lambda sentence: len(word_tokenize(sentence))\n",
    "longest_ans = max(answers, key=ans_count)\n",
    "length_long_ans = len(word_tokenize(longest_ans))\n",
    "print('Longest sentence ='+str(length_long_ans))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 17)\n",
      "(1000, 9)\n"
     ]
    }
   ],
   "source": [
    "padded_questions = pad_sequences(embedded_questions, length_long_question, padding='post')\n",
    "print(padded_questions.shape)\n",
    "padded_answers = pad_sequences(embedded_ans, length_long_ans, padding='post')\n",
    "\n",
    "#padded_answers =  [item[0] for item in padded_answers]\n",
    "print(padded_answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_len,32,input_length=length_long_question))\n",
    "model.add(LSTM(256,dropout=0.2))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(length_long_ans,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 17, 32)            38912     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               295936    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 9)                 2313      \n",
      "=================================================================\n",
      "Total params: 337,161\n",
      "Trainable params: 337,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -942.2549 - acc: 0.6764\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -2229.7433 - acc: 0.5872\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -2941.8209 - acc: 0.5554\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -3620.2277 - acc: 0.5554A: 1s - loss: -3466\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -4278.1558 - acc: 0.5554\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -4929.7634 - acc: 0.5554\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -5575.2449 - acc: 0.5554A: 1s - loss: -53\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -6232.0168 - acc: 0.5554\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -6883.7348 - acc: 0.5554\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -7528.6218 - acc: 0.5554A: 2s - lo\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -8175.3479 - acc: 0.5554\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -8816.9851 - acc: 0.5554\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -9454.5502 - acc: 0.5554\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -10090.4276 - acc: 0.5554\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -10724.4812 - acc: 0.5554\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -11359.7926 - acc: 0.5554\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -11992.2608 - acc: 0.5554: 0s - loss: -12020.4678 - acc\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -12625.0073 - acc: 0.5554\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -13262.2339 - acc: 0.5554\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -13901.9450 - acc: 0.5554: 0s - loss: -13\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -14541.2212 - acc: 0.5554\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -15178.5668 - acc: 0.5554: 0s - loss: -14939.\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -15811.6646 - acc: 0.5554\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -16449.7925 - acc: 0.5554\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -17086.2184 - acc: 0.5554\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -17727.7234 - acc: 0.5554\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -18373.0904 - acc: 0.5554\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -19013.8024 - acc: 0.5554\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -19653.1679 - acc: 0.5554\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -20289.7837 - acc: 0.5554\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -20923.9736 - acc: 0.5554\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -21562.9502 - acc: 0.5554\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -22197.8637 - acc: 0.5554\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -22830.6752 - acc: 0.5554\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -23467.0260 - acc: 0.5554\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -24102.6974 - acc: 0.5554\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -24738.4992 - acc: 0.5554: 0s - loss: -24623.\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -25372.0765 - acc: 0.5554\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -26007.1450 - acc: 0.5554\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -26639.6264 - acc: 0.5554\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -27272.4698 - acc: 0.5554\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -27903.5895 - acc: 0.5554\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -28533.0472 - acc: 0.5554\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -29165.4636 - acc: 0.5554\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -29794.5170 - acc: 0.5554\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -30425.3581 - acc: 0.5554\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -31060.0325 - acc: 0.5554\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -31691.5720 - acc: 0.5554\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -32322.4570 - acc: 0.5554\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -32958.4971 - acc: 0.5554\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: -33587.1527 - acc: 0.5554\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: -34219.1382 - acc: 0.5554\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -34852.3279 - acc: 0.5554\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -35483.6075 - acc: 0.5554\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -36113.2021 - acc: 0.5554\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -36743.6587 - acc: 0.5554\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -37374.8582 - acc: 0.5554\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: -38009.6272 - acc: 0.5554\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -38639.1114 - acc: 0.5554\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -39266.4821 - acc: 0.5554\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: -39900.4924 - acc: 0.5554: 0s - loss: -39965.9766 - acc: \n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -40531.8481 - acc: 0.5554\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -41161.5694 - acc: 0.5554\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -41793.5474 - acc: 0.5554\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -42421.6575 - acc: 0.5554\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -43053.8367 - acc: 0.5554\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -43684.2404 - acc: 0.5554\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -44314.0243 - acc: 0.5554\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -44943.7052 - acc: 0.5554\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -45569.2465 - acc: 0.5554\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: -46202.0348 - acc: 0.5554\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -46830.1518 - acc: 0.5554\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -47461.3690 - acc: 0.5554\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -48091.9299 - acc: 0.5554\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -48721.9849 - acc: 0.5554\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -49352.9721 - acc: 0.5554\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -49986.8836 - acc: 0.5554\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -50618.4696 - acc: 0.5554\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -51248.5684 - acc: 0.5554\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -51878.3086 - acc: 0.5554\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -52508.4206 - acc: 0.5554\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -53138.1894 - acc: 0.5554\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -53770.1379 - acc: 0.5554\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -54401.0908 - acc: 0.5554\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -55033.7365 - acc: 0.5554\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -55666.7054 - acc: 0.5554\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -56295.1463 - acc: 0.5554\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: -56925.6989 - acc: 0.5554\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -57558.7322 - acc: 0.5554\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -58187.1061 - acc: 0.5554\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -58818.1312 - acc: 0.5554\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -59447.3072 - acc: 0.5554\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -60075.2146 - acc: 0.5554\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -60704.7629 - acc: 0.5554\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: -61335.0046 - acc: 0.5554\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -61967.0501 - acc: 0.5554\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -62597.2713 - acc: 0.5554\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -63227.2036 - acc: 0.5554\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -63856.6977 - acc: 0.5554\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: -64485.8895 - acc: 0.5554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23eab7fd8d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_questions,padded_answers,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 2s 23us/step\n",
      "Accuracy: 55.211228\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_questions, padded_answers, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
